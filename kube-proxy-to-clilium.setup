ğŸ¯ Goal

Move from:

Cilium + kube-proxy


To:

Cilium (kube-proxy replacement enabled)


Without breaking networking.

ğŸ§  Step 1 â€” Get Your API Server IP

Since this is kubeadm (not EKS), your API server is running on master.

Run:

kubectl cluster-info


Youâ€™ll see something like:

Kubernetes control plane is running at https://10.0.1.184:6443


ğŸ‘‰ That 10.0.1.184 is your k8sServiceHost.

ğŸ›  Step 2 â€” Upgrade Cilium (Enable kube-proxy replacement)

Now run:

helm upgrade cilium cilium/cilium \
  --namespace kube-system \
  --set kubeProxyReplacement=true \
  --set k8sServiceHost=10.0.1.184 \
  --set k8sServicePort=6443


(Replace IP if different.)

This tells Cilium:

"You handle service routing now. Not kube-proxy."

â³ Step 3 â€” Wait for rollout
kubectl -n kube-system rollout status daemonset/cilium


Wait until it says successfully rolled out.

ğŸ” Step 4 â€” Verify Replacement Is Active

Run:

kubectl -n kube-system exec ds/cilium -- cilium status


Look for:

KubeProxyReplacement:   Strict


If you see Strict â†’ ğŸ”¥ youâ€™re fully running eBPF service routing.

ğŸ§¨ Step 5 â€” Remove kube-proxy (ONLY After Confirming)

Once status is good:

kubectl -n kube-system delete ds kube-proxy


Check:

kubectl get pods -A


Test:

kubectl run test --image=nginx
kubectl expose pod test --port=80


Access service from another pod.

If it works â†’ youâ€™re golden.

ğŸ§  What Just Happened Under the Hood?

Before:

Pod â†’ iptables â†’ kube-proxy â†’ Service â†’ Pod


Now:

Pod â†’ eBPF (kernel-level) â†’ Service â†’ Pod


No iptables.
No kube-proxy.
Lower latency.
Better scalability.
